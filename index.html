<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>COS 436 Final Presentations</title>
    <link rel="stylesheet" href="static/style.css">
    <link rel="stylesheet"
      href="https://fonts.googleapis.com/css?family=Roboto">
    <link rel="stylesheet"
      href="https://fonts.googleapis.com/css?family=Nunito+Sans">
    <link rel="stylesheet"
      href="https://fonts.googleapis.com/css?family=Roboto+Mono">
	<link rel="stylesheet"
      href="https://fonts.googleapis.com/css?family=EB+Garamond">
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous">
	<meta name="msapplication-TileImage" content="https://i0.wp.com/hci.princeton.edu/wp-content/uploads/sites/459/2020/11/cropped-favicon.png?fit=270%2C270&amp;ssl=1">
	<link rel="icon" href="https://i0.wp.com/hci.princeton.edu/wp-content/uploads/sites/459/2020/11/cropped-favicon.png?fit=32%2C32&amp;ssl=1" sizes="32x32">
	<link rel="icon" href="https://i0.wp.com/hci.princeton.edu/wp-content/uploads/sites/459/2020/11/cropped-favicon.png?fit=192%2C192&amp;ssl=1" sizes="192x192">
	<link rel="apple-touch-icon" href="https://i0.wp.com/hci.princeton.edu/wp-content/uploads/sites/459/2020/11/cropped-favicon.png?fit=180%2C180&amp;ssl=1">
  </head>
  <body>

	<nav class="navbar navbar-expand-lg navbar-light bg-light sticky-top">
		<div class="container">
		<a class="navbar-brand" href="#">COS 436 Fall 2023</a>
		<button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
		  <span class="navbar-toggler-icon"></span>
		</button>
		<div class="collapse navbar-collapse" id="navbarNav">
		  <ul class="navbar-nav">
			<li class="nav-item"><a class="nav-link" href="#summaryreport">Report</a></li>
			<li class="nav-item"><a class="nav-link" href="#summaryvideo">Video</a></li>
			<!-- <li class="nav-item"><a class="nav-link" href="#projects">Projects</a></li> -->
			<li class="nav-item"><a class="nav-link" href="#systemprojects">System Projects</a></li>
			<li class="nav-item"><a class="nav-link" href="#studyprojects">Study Projects</a></li>
		  </ul>
		</div>
	</div>
	</nav>

    <div class="main-content container">
    	<div id="home">
			<h1>COS 436 Human-Computer Interaction</h1>
			<h2>Final Projects</h2>
			<h2>Fall 2023</h2>
			<h2>Princeton University</h2>
			<br>
		</div>

		<section id="summaryreport">
			<div class="article">
				<h2 class="articletitle">HCI Projects of 2023: Presenting 16 Novel Systems and Studies</h2>
				<p class="articledata">December 7, 2023</p>
				<p><span class="firstletter">O</span>n a sunny Thursday afternoon, the Friend Center atrium bustled with activity, students gathered around orange tables adorned with presentation slides and exciting projects. It’s November 30th, the day of the final Project Fair for the students enrolled in COS 436: Human-Computer Interaction.</p>
				<div class="collage-image-container">
					<img alt="photo from Project Fair Round II." src="img/project-fair-round-ii.png">
					<div class="collage-image-caption">Photo from Project Fair Round II caption</div>
				</div>
				<p>The course, taught by Professors Andrés Monroy-Hernández and Parastoo Abtahi, offers a survey of the broad field of Human-Computer Interaction (HCI), with a focus on interactive and social computing. Over the semester, the students completed group projects that either implemented an interactive system or conducted a study on an HCI topic.</p>
				<p>The 16 projects covered a wide variety of subfields within HCI, from exploring how people interact with AI such as  ChatGPT and Dall-E, to building systems to help with mental health or leveraging AR for improving education. Here is a summary of the HCI Projects of 2023:</p>
				<ol>
					<li>
						<p class="articlesubtitle">How do conversational UIs compare to textual prompts for AI image generation? </p>
						<p class="articleauthor">Henry Knoll, Ava Crnkovic-Rubsamen, Mike Scornavacca, and Pierce Maloney</p>
						<p>This project investigated whether single-prompt or conversational approaches to prompting image generation were more desirable to users. The group found that most users preferred a more conversational approach to image generation.</p>
					</li>
					<li>
						<p class="articlesubtitle">BÆ-I</p>
						<p class="articleauthor">Alison Lee, Ambri Ma, Christine Sun, Harvey Wang</p>
						<p>This project tested how AI-generated prompts could solve the problem of remote socialization. The system, BÆ-I, allows partners to ask each other questions, then choose between their partner’s and two AI-generated responses. Couples reported increases in quality of communication and some other relationship metrics after playing.</p>
					</li>
					<li>
						<p class="articlesubtitle">What do student artists think of AI?</p>
						<p class="articleauthor">Kellen Cao and Rhim Andemichael</p>
						<p>This project investigated the attitudes of student artists at Princeton with regards to AI-generated art, along with their ability to distinguish human-generated art from AI-generated art. They found mixed attitudes from excitement to disillusionment. They also found that AI-generated art with human elements was more likely to fool student artists.</p>
					</li>
					<li>
						<p class="articlesubtitle">ChatGPT in CS education</p>
						<p class="articleauthor">Ariana Lujan, Joy Patterson, Divraj Singh, Alexis Wu</p>
						<p>This group asked a wide range of educators on their views on the use of ChatGPT in CS education. They asked about problems including LLM hallucination, attribution of generated code, and the relation of LLMs to critical thinking skills. Educators surveyed were more likely than not to incorporate LLMs into course policies or within the classroom, but were often concerned about their long-term impacts.</p>
					</li>
					<!-- <span><li></li></span> -->
					<li value="6">
						<p class="articlesubtitle">Exploring the visuo-vibrotactile modality for real-time low-friction feedback in the classroom</p>
						<p class="articleauthor">Oleg Golev, Michelle Huang, Chanketya Nop, Kritin Vongthongsri</p>
						<p>Group 6 looked at applying real-time, low-friction feedback to the problem of delayed instructor reactions. They did so by building a system that allowed students to send haptic feedback to instructors’ smart watches based on their current sentiments.</p>
					</li>
					<li>
						<p class="articlesubtitle">How well does AI-generated speculative design solve the problem of myopic ethical considerations for emerging technologies?</p>
						<p class="articleauthor">Libo Tan, Andrew Mi, Kok Wei Pua, and Jordan Bowman-Davis</p>
						<p>This project explored the use of AI generation to prompt participants to explore ethical questions. They built a system where users could ask AI-generated clones of themselves questions, with live feedback. This resulted in users having various conversations, but those generally were not ethical in nature.</p>
					</li>
					<li>
						<p class="articlesubtitle">How well do AR visualizations solve the problem of bystander safety, comfort, and trust for virtual mobile robots?</p>
						<p class="articleauthor">Maya Jairam, Advika Srivastava, Ananya Grover, Devansh Sharma</p>
						<p>Group 8 aimed to investigate the efficacy of AR in allowing users to understand the movements of robots. To do so, they virtually emulated a delivery robot within AR, and used a system of cues in order to allow users to understand its upcoming actions.</p>
					</li>
					<li>
						<p class="articlesubtitle">Breaking The Plane</p>
						<p class="articleauthor">Liam Esparraguera, Brian Lou, Kris Selberg, Jenny Sun</p>
						<p>This group aimed to address the difficulty of understanding higher-dimensional mathematics using AR. To do so, they built a system enabling users to visualize and manipulate three-dimensional equations on a Quest 3, combined with OCR equation input. They found users generally preferred this system to alternatives.</p>
					</li>
					<li>
						<p class="articlesubtitle">Lemme See That!: Examining how AI Art impacts engagement with textual posts on X </p>
						<p class="articleauthor">Okezie Eze, Samyukta Neeraj, Meet Patel, Dylan Tran</p>
						<p>This project leverages X’s unique outreach (and an incredible amount of available data) to explore AI's potential in different social media contexts (such as marketing, advertisement, and research). They used Selenium to scrape data, grab Tweets from the “Latest” section, and then they manually assigned features for the images. They found that there was higher engagement on posts with human generated images, compared to that of posts with no images or AI-generated images.</p>
					</li>
					<li>
						<p class="articlesubtitle">How do college students use ChatGPT to learn to code?</p>
						<p class="articleauthor">Kuba Alicki, Tolulope Oshinowo, Yuhan Zheng, Seanna Zhang</p>
						<p>This project explores how university students have used ChatGPT in the space of learning new programming languages. They conducted a survey interviewed fellow Princeton students, and studied their experience with ChatGPT and its educational potential. Results showed that while almost all participants used ChatGPT to check syntax or generate snippets, new learners/beginners relied on ChatGPT’s output way too heavily, leading to a less effective learning environment.</p>
					</li>
					<li>
						<p class="articlesubtitle">How do non-native English speakers use ChatGPT as a tool for writing?</p>
						<p class="articleauthor">Jasmine Zhang, Desmond Devalu, Theo Knoll, and Emmy Song</p>
						<p>This project is centered around how ChatGPT can enhance the efficiency and accuracy of writing done by non-native English speakers. The study found that ChatGPT helped participants construct responses significantly more efficiently for long-form responses, but in short-form, such as text messages, the efficiency was actually worse.</p>
					</li>
					<li>
						<p class="articlesubtitle">Understanding Visual Artists' Perspectives on Their Use of Generative AI</p>
						<p class="articleauthor">Genie Choi, Lu Esteban, Kirsten Pardo, Warren Quan</p>
						<p>This study explores how artists perceive the use of generative AI tools, with a focus on ethical and artistic considerations. Both professional and student artists were interviewed, and their usage of AI was questioned. The results showed quite an interesting division between artists who do not use AI tools at all and others who use it religiously. As expected, these two groups had very different outlooks on AI's ethical and artistic use cases throughout art.</p>
					</li>
					<li>
						<p class="articlesubtitle">Understanding College Students’ Opinions on LLM-assisted Mental Health Services</p>
						<p class="articleauthor">Owen Zhang, Shuyao Zhou, Jiayi Geng</p>
						<p>This project explores the potential of Large Language Models (LLMs) in the context of mental health services throughout a college campus. Researchers asked questions regarding possible benefits, concerns, and/or expectations when using applications based on LLM technology for support in mental health. Preliminary research uncovered opinions such that participants expected LLMs to be proactive and general concerns of LLMs variety in training data on mental health.</p>
					</li>
					<li>
						<p class="articlesubtitle">Public Perception of Front-Facing Display Headsets</p>
						<p class="articleauthor">Dariya Brann, Ryan Vuono, Henry Wertz</p>
						<p>This study focuses on how the public perceives virtual reality headsets that feature front-facing displays. Information was gathered via online surveys and follow-up interviews with volunteering participants, and questions were asked surrounding the naturalness of the conversation and its effect on the conversation’s efficacy. The results revealed widespread hesitation towards such technology and thus suggested that current headsets are not yet suitable for daily use in social interactions.</p>
					</li>
					<li>
						<p class="articlesubtitle">RateRight: Reducing Extremity Bias in Online Reviews - A Low-Friction, Time, and Location-Based Approach</p>
						<p class="articleauthor">Arnav Kumar, Darius Jankauskas, Stephen Dong</p>
						<p>This project proposed an innovative system to produce more authentic and accurate ratings for lectures. It leverages native iOS and Android notifications to allow users to immediately respond to lectures and provide feedback and a rating, and filters based on the users’ locations. The results showed that users were more likely to leave a review and that this greater range of reviews could ideally reduce the extreme nature of online reviews.</p>
					</li>
					<li>
						<p class="articlesubtitle">Evaluating the Effectiveness of Asynchronous Collaboration in Remote Design Environments</p>
						<p class="articleauthor">Darren Alexis, Jakob Nogler, Ruyu Yan</p>
						<p>This project focuses on remote collaboration in the context of 3-dimensional designs, as opposed to document collaboration (like Google Docs) or 2D design (such as Figma). The study followed 6 participants with experience in artistic design as they attempted to collaborate on coloring and adjusting a scanned model. The results show that despite some promising applications, the effectiveness of such a tool is limited by the interface and communication between participants.</p>
					</li>
				</ol>

				<div class="collage-image-container">
					<img alt="A collage of images representing the group’s projects. Several images generated using Dall-E." src="img/">
					<div class="collage-image-caption">A collage of images representing the group’s projects. Several images generated using Dall-E.</div>
				</div>
				<p>	These projects not only pushed the boundaries of HCI but also illuminated the dynamic interplay between humans and technology. From AI's influence on socialization to AR's role in robotics, these projects exemplify the diverse facets of HCI and its multidisciplinary nature. We hope you have been inspired to reflect on how you interact with technology in your day-to-day life, and how systems like these can transform the way you work, learn, or communicate.</p>
				<p>As this year draws to a close, we are grateful to the students and professors of COS 436 for contributing and sharing these incredible projects. We look forward to the work of the next students of COS 436: Human-Computer Interaction.</p>


				
			</div>
		</section>

		<section id="summaryvideo" class="notdone">
			<h2>Summary Video</h2>
			<div class="center"><iframe 
				width="560" height="315" src="https://www.youtube.com/embed/1iimVd-2Fx8?si=CUDG2cRdDqQcRg9C" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></div>
		</section>
	
		<div id="projects">
			<section id="systemprojects">
			<h2>System Implementation Projects</h2>
				<div class="row">
					<div class="col-sm-12 col-md-12 col-lg-6 col-xl-3 col-xxl-3">
						<div class="project-card">
						<div class="group-name">Team 1</div>
						<div class="project-name">How do conversational UIs (CUIs) compare to textual prompts for AI-generated images?</div>
						<div class="project-summary">Group 1 investigated whether single-prompt or conversational approaches to prompting image generation were more desirable to users. The group found that most users preferred a more conversational approach to image generation.</div>
						<div class="collage-image-container mx-auto"><img alt="" src="img/team1.png"></div>
						<div class="collage-image-caption">A picture of a dog on a beach, generated with Group 1’s conversational image generation prompting system.</div>
						<div class="collage-image-caption">[Team 1’s Presentation]</div>
						<div class="team-members">Mike Scornavacca, Pierce Maloney, Ava Crnkovic-Rubsamen, Henry Knoll</div>
						</div>
					</div>
					<div class="col-sm-12 col-md-12 col-lg-6 col-xl-3 col-xxl-3">
						<div class="project-card">
						<div class="group-name">Team 2</div>
						<div class="project-name">BÆ-I</div>
						<div class="project-summary">Group 2 devised a system to test how AI-generated prompts could solve the problem of remote socialization. Their system, BÆ-I, allows partners to ask each other questions, then choose between their partner’s and two AI-generated responses. Couples reported increases in quality of communication and some other relationship metrics after playing.</div>
						<div class="collage-image-container"><img alt="" src="img/team2.png"></div>
						<div class="collage-image-caption">The flow of a BÆ-I game on Discord, from start to an incorrect guess.</div>
						<div class="collage-image-caption">[Team 2’s Project Fair Round 2 report]</div>
						<div class="team-members">Alison Lee, Ambri Ma, Christine Sun, Harvey Wang</div>
						</div>
					</div>
					<div class="col-sm-12 col-md-12 col-lg-6 col-xl-3 col-xxl-3">
						<div class="project-card">
						<div class="group-name">Team 3</div>
						<div class="project-name">Artists and AI: The Opinions of Young Artists on Generative Art</div>
						<div class="project-summary">Group 3 investigated the attitudes of student artists at Princeton with regards to AI-generated art, along with their ability to distinguish human-generated art from AI-generated art. They found mixed attitudes from excitement to disillusionment. They also found that AI-generated art with human elements was more likely to fool student artists.</div>
						<div class="collage-image-container"><img alt="" src="img/team3.png"></div>
						<div class="collage-image-caption">A Princeton student concerned by his experience with AI-generated art.</div>
						<div class="collage-image-caption">[Generated by DALLE-3]</div>
						<div class="team-members">Kellen Cao & Rhim Andemichael</div>
						</div>
					</div>
					<div class="col-sm-12 col-md-12 col-lg-6 col-xl-3 col-xxl-3">
						<div class="project-card">
						<div class="group-name">Team 4</div>
						<div class="project-name">ChatGPT in CS Education</div>
						<div class="project-summary">Group 4 asked a wide range of educators on their views on the use of ChatGPT in CS education. They asked about problems including LLM hallucination, attribution of generated code, and the relation of LLMs to critical thinking skills. Educators surveyed were more likely than not to incorporate LLMs into course policies or within the classroom, but were often concerned about their long-term impacts. </div>
						<div class="collage-image-container"><img alt="" src="img/team4.png"></div>
						<div class="collage-image-caption">Students and educators are grappling with the promise and perils of LLMs in an educational context.</div>
						<div class="collage-image-caption">[Group 4’s presentation video]</div>
						<div class="team-members">Alexis Wu, Ariana Lujan, Divraj Singh, Joy Patterson</div>
						</div>
					</div>
				</div>

				<div class="row">
					<div class="col-sm-12 col-md-12 col-lg-6 col-xl-3 col-xxl-3">
						<div class="project-card">
						<div class="group-name">Team 6</div>
						<div class="project-name">Exploring the Visuo-Vibrotactile Modality for Real-Time Low-Friction Feedback in the Classroom</div>
						<div class="project-summary">Group 6 looked at applying real-time, low-friction feedback to the problem of delayed instructor reactions. They did so by building a system that allowed students to send haptic feedback to instructors’ smart watches based on their current sentiments. </div>
						<div class="collage-image-container"><img alt="" src="img/team6.png"></div>
						<div class="collage-image-caption">An instructor’s visual view of live student reactions.</div>
						<div class="collage-image-caption"> [Group 6’s presentation video]</div>
						<div class="team-members">Oleg Golev, Michelle Huang, Chanketya Nop, Kritin Vongthongsri</div>
						</div>
					</div>
					<div class="col-sm-12 col-md-12 col-lg-6 col-xl-3 col-xxl-3">
						<div class="project-card">
						<div class="group-name">Team 7</div>
						<div class="project-name">How well does AI-generated speculative design solve the problem of myopic ethical considerations for emerging technologies?</div>
						<div class="project-summary">Group 7 explored the use of AI generation to prompt participants to explore ethical questions. They built a system where users could ask AI-generated clones of themselves questions, with live feedback. This resulted in users having various conversations, but those generally were not ethical in nature.</div>
						<div class="collage-image-container"><img alt="" src="img/team7.png"></div>
						<div class="collage-image-caption">AI-generated Bill Gates with miscellaneous beaker.</div>
						<div class="collage-image-caption">[Quartz-generated, from Group 7]</div>
						<div class="team-members">Libo Tan, Andrew Mi, Kok Wei Pua, and Jordan Bowman-Davis</div>
						</div>
					</div>
					<div class="col-sm-12 col-md-12 col-lg-6 col-xl-3 col-xxl-3">
						<div class="project-card">
						<div class="group-name">Team 8</div>
						<div class="project-name">How well do AR visualizations solve the problem of bystander safety, comfort, and trust for virtual mobile robots?</div>
						<div class="project-summary">Group 8 aimed to investigate the efficacy of AR in allowing users to understand the movements of robots. To do so, they virtually emulated a delivery robot within AR, and used a system of cues in order to allow users to understand its upcoming actions.</div>
						<div class="collage-image-container"><img alt="" src="img/team8.png"></div>
						<div class="collage-image-caption">A delivery robot rendered in AR, along with a directional cue indicating its future direction. </div>
						<div class="collage-image-caption">[Group 8’s aero_recording.mov]</div>
						<div class="team-members">Maya Jairam, Devansh Sharma, Ananya Grover</div>
						</div>
					</div>
					<div class="col-sm-12 col-md-12 col-lg-6 col-xl-3 col-xxl-3">
						<div class="project-card">
						<div class="group-name">Team 9</div>
						<div class="project-name">Breaking The Plane: How do 3D Augmented Reality (AR) visualizations with AR headsets compare to mobile AR and flat-screen visualizations for understanding multidimensional mathematical concepts?</div>
						<div class="project-summary">Group 9 aimed to address the difficulty of understanding higher-dimensional mathematics using AR. To do so, they built a system enabling users to visualize and manipulate three-dimensional equations on a Quest 3, combined with OCR equation input. They found users generally preferred this system to alternatives.</div>
						<div class="collage-image-container"><img alt="" src="img/team9.png"></div>
						<div class="collage-image-caption">A screen capture of the system’s AR visualization from a Quest 3 device.</div>
						<div class="collage-image-caption">[Group 9’s presentation]</div>
						<div class="team-members">Liam Esparraguera, Brian Lou, Kris Selberg, Jenny Sun</div>
						</div>
					</div>
				</div>
			</section>

			<section id="studyprojects">
			<h2>Study Projects</h2>
				<div class="row">
					<div class="col-sm-12 col-md-12 col-lg-6 col-xl-3 col-xxl-3">
						<div class="project-card">
						<div class="group-name">Team 10</div>
						<div class="project-name">Lemme See That!: Examining how AI Art impacts engagement with textual posts on X</div>
						<div class="project-summary">This project leverages X’s unique outreach (and an incredible amount of available data) to explore AI's potential in different social media contexts (such as marketing, advertisement, and research). They used Selenium to scrape data, grab Tweets from the “Latest” section, and then they manually assigned features for the images. They found that there was higher engagement on posts with human generated images, compared to that of posts with no images or AI-generated images.</div>
						<div class="collage-image-container"><img alt="" src="img/team10.png"></div>
						<!-- <div class="collage-image-caption"></div> -->
						<div class="collage-image-caption">[Generated by DALL-E]</div>
						<div class="team-members">Okezie Eze, Samyukta Neeraj, Meet Patel, Dylan Tran</div>
						</div>
					</div>	
					<div class="col-sm-12 col-md-12 col-lg-6 col-xl-3 col-xxl-3">
						<div class="project-card">
						<div class="group-name">Team 11</div>
						<div class="project-name">How do college students use ChatGPT to learn to code?</div>
						<div class="project-summary">This project explores how university students have used ChatGPT in the space of learning new programming languages. They conducted a survey interviewed fellow Princeton students, and studied their experience with ChatGPT and its educational potential. Results showed that while almost all participants used ChatGPT to check syntax or generate snippets, new learners/beginners relied on ChatGPT’s output way too heavily, leading to a less effective learning environment.</div>
						<div class="collage-image-container"><img alt="" src="img/team11.png"></div>
						<!-- <div class="collage-image-caption"></div> -->
						<div class="collage-image-caption">[Generated by DALL-E]</div>
						<div class="team-members">Kuba Alicki, Tolulope Oshinowo, Yuhan Zheng, Seanna Zhang</div>
						</div>
					</div>	
					<div class="col-sm-12 col-md-12 col-lg-6 col-xl-3 col-xxl-3">
						<div class="project-card">
						<div class="group-name">Team 12</div>
						<div class="project-name">How do non-native English speakers use ChatGPT as a tool for writing?</div>
						<div class="project-summary">This project is centered around how ChatGPT can enhance the efficiency and accuracy of writing done by non-native English speakers. The study found that ChatGPT helped participants construct responses significantly more efficiently for long-form responses, but in short-form, such as text messages, the efficiency was actually worse.</div>
						<div class="collage-image-container"><img alt="" src="img/team12.png"></div>
						<!-- <div class="collage-image-caption"></div> -->
						<div class="collage-image-caption">[Generated by DALL-E]</div>
						<div class="team-members">Jasmine Zhang, Desmond Devalu, Theo Knoll, and Emmy Song</div>
						</div>
					</div>	
					<div class="col-sm-12 col-md-12 col-lg-6 col-xl-3 col-xxl-3">
						<div class="project-card">
						<div class="group-name">Team 13</div>
						<div class="project-name">Understanding Visual Artists' Perspectives on Their Use of Generative AI</div>
						<div class="project-summary">This study explores how artists perceive the use of generative AI tools, with a focus on ethical and artistic considerations. Both professional and student artists were interviewed, and their usage of AI was questioned. The results showed quite an interesting division between artists who do not use AI tools at all and others who use it religiously. As expected, these two groups had very different outlooks on AI's ethical and artistic use cases throughout art.</div>
						<div class="collage-image-container"><img alt="" src="img/team13.png"></div>
						<!-- <div class="collage-image-caption"></div> -->
						<div class="collage-image-caption">[Generated by DALL-E]</div>
						<div class="team-members">Genie Choi, Lu Esteban, Kirsten Pardo, Warren Quan</div>
						</div>
					</div>	
				</div>

				<div class="row">
					<div class="col-sm-12 col-md-12 col-lg-6 col-xl-3 col-xxl-3">
						<div class="project-card">
						<div class="group-name">Team 14</div>
						<div class="project-name">Understanding College Students’ Opinions on LLM-assisted Mental Health Services</div>
						<div class="project-summary"> This project explores the potential of Large Language Models (LLMs) in the context of mental health services throughout a college campus. Researchers asked questions regarding possible benefits, concerns, and/or expectations when using applications based on LLM technology for support in mental health. Preliminary research uncovered opinions such that participants expected LLMs to be proactive and general concerns of LLMs variety in training data on mental health.</div>
						<div class="collage-image-container"><img alt="" src="img/team14.png"></div>
						<!-- <div class="collage-image-caption"></div> -->
						<div class="collage-image-caption">[Generated by DALL-E]</div>
						<div class="team-members">Owen Zhang, Shuyao Zhou, Jiayi Geng</div>
						</div>
					</div>	
					<div class="col-sm-12 col-md-12 col-lg-6 col-xl-3 col-xxl-3">
						<div class="project-card">
						<div class="group-name">Team 15</div>
						<div class="project-name">Public Perception of Front-Facing Display Headsets</div>
						<div class="project-summary">This study focuses on how the public perceives virtual reality headsets that feature front-facing displays. Information was gathered via online surveys and follow-up interviews with volunteering participants, and questions were asked surrounding the naturalness of the conversation and its effect on the conversation’s efficacy. The results revealed widespread hesitation towards such technology and thus suggested that current headsets are not yet suitable for daily use in social interactions.</div>
						<div class="collage-image-container"><img alt="" src="img/team15.png"></div>
						<!-- <div class="collage-image-caption"></div> -->
						<div class="collage-image-caption">[Generated by DALL-E]</div>
						<div class="team-members">Dariya Brann, Ryan Vuono, Henry Wertz</div>
						</div>
					</div>	
					<div class="col-sm-12 col-md-12 col-lg-6 col-xl-3 col-xxl-3">
						<div class="project-card">
						<div class="group-name">Team 16</div>
						<div class="project-name">RateRight: Reducing Extremity Bias in Online Reviews - A Low-Friction, Time, and Location-Based Approach</div>
						<div class="project-summary">This project proposed an innovative system to produce more authentic and accurate ratings for lectures. It leverages native iOS and Android notifications to allow users to immediately respond to lectures and provide feedback and a rating, and filters based on the users’ locations. The results showed that users were more likely to leave a review and that this greater range of reviews could ideally reduce the extreme nature of online reviews.</div>
						<div class="collage-image-container"><img alt="" src="img/team16.png"></div>
						<!-- <div class="collage-image-caption"></div> -->
						<div class="collage-image-caption">[Generated by DALL-E]</div>
						<div class="team-members">Arnav Kumar, Darius Jankauskas, Stephen Dong</div>
						</div>
					</div>	
					<div class="col-sm-12 col-md-12 col-lg-6 col-xl-3 col-xxl-3">
						<div class="project-card">
						<div class="group-name">Team 17</div>
						<div class="project-name">Evaluating the Effectiveness of Asynchronous Collaboration in Remote Design Environments</div>
						<div class="project-summary">This project focuses on remote collaboration in the context of 3-dimensional designs, as opposed to document collaboration (like Google Docs) or 2D design (such as Figma). The study followed 6 participants with experience in artistic design as they attempted to collaborate on coloring and adjusting a scanned model. The results show that despite some promising applications, the effectiveness of such a tool is limited by the interface and communication between participants.</div>
						<div class="collage-image-container"><img alt="" src="img/team17.png"></div>
						<!-- <div class="collage-image-caption"></div> -->
						<div class="collage-image-caption">[Generated by DALL-E]</div>
						<div class="team-members">Darren Alexis, Jakob Nogler, Ruyu Yan</div>
						</div>
					</div>	
					<p>NOTE: ChatGPT was used to provide a brief summary of project results to best capture each project's essence in only a few sentences. The information collected from these responses was then used as part of an overall summary of the entire project, self-created from project fair reports, proposals, and presentations.</p>
				</div>
			</section>
		</div>

    </div>
  </body>
</html>
